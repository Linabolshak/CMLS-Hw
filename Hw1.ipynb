{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "Hw1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mUOrAYas_mL",
        "colab_type": "text"
      },
      "source": [
        "# Genre Classification using Support-vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkd5eD5Ys_mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.svm\n",
        "import IPython.display as ipd\n",
        "import scipy as sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vKqvXRyIIba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git #directly clone the directory from github"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax7y26_ks_mR",
        "colab_type": "text"
      },
      "source": [
        "# Feature computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwcXOr9_s_mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_mfcc(audio, fs, n_mfcc):\n",
        "    # Compute the spectrogram of the audio signal\n",
        "    X = np.abs(librosa.stft(\n",
        "        audio,\n",
        "        window='hamming',\n",
        "        n_fft=1024,\n",
        "        hop_length=512,)\n",
        "        )\n",
        "    \n",
        "    # Find the weights of the mel filters\n",
        "    mel = librosa.filters.mel(\n",
        "        sr=fs,\n",
        "        n_fft=1024,\n",
        "        n_mels=40,\n",
        "        fmin=133.33,\n",
        "        fmax=6853.8,\n",
        "    )\n",
        "    # Apply the filters to spectrogram\n",
        "    melspectrogram = np.dot(mel, X)\n",
        "    # Take the logarithm\n",
        "    log_melspectrogram = np.log10(melspectrogram + 1e-16)\n",
        "    \n",
        "    # Apply the DCT to log melspectrogram to obtain the coefficients\n",
        "    mfcc = sp.fftpack.dct(log_melspectrogram, axis=0, norm='ortho')[1:n_mfcc+1]\n",
        "    return mfcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PeXRTB-s_mV",
        "colab_type": "text"
      },
      "source": [
        "### Compute training features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL3mBDL7s_mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "test = []\n",
        "train = []\n",
        "n_mfcc = 13\n",
        "dict_train_files = {'0': [], '1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': [], '8': [], '9': []}\n",
        "dict_train_features = {'0': [], '1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': [], '8': [], '9': []}\n",
        "\n",
        "train_root = 'free-spoken-digit-dataset/recordings'\n",
        "class_train_files = [f for f in os.listdir(train_root) if f.endswith('.wav')] #outputs a list with the filename of every file in train_root\n",
        "\n",
        "#Splits dataset in test and train\n",
        "for f in class_train_files:\n",
        "  first_split = f.rsplit(\"_\", 1)[1]\n",
        "  second_split = first_split.rsplit(\".\", 1)[0]\n",
        "  if int(second_split) <= 4:\n",
        "      test.append(f)\n",
        "  else:\n",
        "      train.append(f)\n",
        "\n",
        "#Puts files name in dict_train_files according to class\n",
        "for c in classes:\n",
        "  for f in train:\n",
        "    split = f.rsplit(\"_\", 2)[0]\n",
        "    if int(c) == int(split):\n",
        "      dict_train_files[c].append(f)\n",
        "\n",
        "#Computes feature matrix according to class and puts it into dict_train_features\n",
        "for c in dict_train_files:\n",
        "  \n",
        "  train_features = np.zeros((len(dict_train_files[c]), n_mfcc)) # \n",
        "  \n",
        "  for index, f in enumerate(dict_train_files[c]):\n",
        "    audio, fs = librosa.load(os.path.join(train_root, f), sr=None)\n",
        "    mfcc = compute_mfcc(audio, fs, n_mfcc)\n",
        "    train_features[index, :] = np.mean(mfcc, axis=1)\n",
        "    \n",
        "    dict_train_features[c] = train_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16W94wkZs_me",
        "colab_type": "text"
      },
      "source": [
        "### Compute test features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXR_JRFds_mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#same as above for test set\n",
        "dict_test_files = {'0': [], '1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': [], '8': [], '9': []}\n",
        "dict_test_features = {'0': [], '1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': [], '8': [], '9': []}\n",
        "\n",
        "for c in classes:\n",
        "  for f in test:\n",
        "    splitto = f.rsplit(\"_\", 2)[0]\n",
        "    if int(c) == int(splitto):\n",
        "      dict_test_files[c].append(f)\n",
        "\n",
        "\n",
        "for c in dict_test_files:\n",
        "  \n",
        "  n_test_samples = len(dict_test_files[c]) #outputs length of class_train_files \n",
        "  \n",
        "  test_features = np.zeros((n_test_samples, n_mfcc))  \n",
        "  \n",
        "  for index, f in enumerate(dict_test_files[c]):\n",
        "    audio, fs = librosa.load(os.path.join(train_root, f), sr=None)\n",
        "    mfcc = compute_mfcc(audio, fs, n_mfcc)\n",
        "    test_features[index, :] = np.mean(mfcc, axis=1)\n",
        "    \n",
        "  dict_test_features[c] = test_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-TsMwwps_ml",
        "colab_type": "text"
      },
      "source": [
        "### Feature visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qQH4Bw45s_mm",
        "colab_type": "code",
        "outputId": "38437aa9-144f-40b2-fa4b-31d9e7eac8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for c in classes:\n",
        "    mfcc = dict_train_features[c].transpose()\n",
        "    # Visualization\n",
        "    fig = plt.figure(figsize=(16, 6))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(mfcc, origin='lower', aspect='auto')\n",
        "    plt.xlabel('Training samples')\n",
        "    plt.ylabel('MFCC coefficients')\n",
        "    plt.title('MFCC (coefficients 0 to 13) for class {}'.format(c))\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    mfcc_upper = mfcc[4:]\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mfcc_upper, origin='lower', aspect='auto')\n",
        "    plt.title('MFCC (coefficients 4 to 13) for class {}'.format(c))\n",
        "    plt.xlabel('Training samples')\n",
        "    plt.ylabel('MFCC coefficients')\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqhR_03bs_nL",
        "colab_type": "text"
      },
      "source": [
        "# SVM: multiclass case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbTQgZbTs_nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_0 = '0'\n",
        "class_1 = '1'\n",
        "class_2 = '2'\n",
        "class_3 = '3'\n",
        "class_4 = '4'\n",
        "class_5 = '5'\n",
        "class_6 = '6'\n",
        "class_7 = '7'\n",
        "class_8 = '8'\n",
        "class_9 = '9'\n",
        "\n",
        "#Training\n",
        "X_train_0 = dict_train_features[class_0]\n",
        "X_train_1 = dict_train_features[class_1]\n",
        "X_train_2 = dict_train_features[class_2]\n",
        "X_train_3 = dict_train_features[class_3]\n",
        "X_train_4 = dict_train_features[class_4]\n",
        "X_train_5 = dict_train_features[class_5]\n",
        "X_train_6 = dict_train_features[class_6]\n",
        "X_train_7 = dict_train_features[class_7]\n",
        "X_train_8 = dict_train_features[class_8]\n",
        "X_train_9 = dict_train_features[class_9]\n",
        "\n",
        "y_train_0 = np.zeros((X_train_0.shape[0]))\n",
        "y_train_1 = np.ones((X_train_1.shape[0]))\n",
        "y_train_2 = np.full((X_train_2.shape[0]), 2)\n",
        "y_train_3 = np.full((X_train_3.shape[0]), 3)\n",
        "y_train_4 = np.full((X_train_4.shape[0]), 4)\n",
        "y_train_5 = np.full((X_train_5.shape[0]), 5)\n",
        "y_train_6 = np.full((X_train_6.shape[0]), 6)\n",
        "y_train_7 = np.full((X_train_7.shape[0]), 7)\n",
        "y_train_8 = np.full((X_train_8.shape[0]), 8)\n",
        "y_train_9 = np.full((X_train_9.shape[0]), 9)\n",
        "\n",
        "y_train_mc = np.concatenate((y_train_0, y_train_1, y_train_2, y_train_3, y_train_4, y_train_5, y_train_6, y_train_7, y_train_8, y_train_9), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RIdle9Os_nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing\n",
        "X_test_0 = dict_test_features[class_0]\n",
        "X_test_1 = dict_test_features[class_1]\n",
        "X_test_2 = dict_test_features[class_2]\n",
        "X_test_3 = dict_test_features[class_3]\n",
        "X_test_4 = dict_test_features[class_4]\n",
        "X_test_5 = dict_test_features[class_5]\n",
        "X_test_6 = dict_test_features[class_6]\n",
        "X_test_7 = dict_test_features[class_7]\n",
        "X_test_8 = dict_test_features[class_8]\n",
        "X_test_9 = dict_test_features[class_9]\n",
        "\n",
        "y_test_0 = np.zeros((X_test_0.shape[0]))\n",
        "y_test_1 = np.ones((X_test_1.shape[0]))\n",
        "y_test_2 = np.full((X_test_2.shape[0]), 2)\n",
        "y_test_3 = np.full((X_test_3.shape[0]), 3)\n",
        "y_test_4 = np.full((X_test_4.shape[0]), 4)\n",
        "y_test_5 = np.full((X_test_5.shape[0]), 5)\n",
        "y_test_6 = np.full((X_test_6.shape[0]), 6)\n",
        "y_test_7 = np.full((X_test_7.shape[0]), 7)\n",
        "y_test_8 = np.full((X_test_8.shape[0]), 8)\n",
        "y_test_9 = np.full((X_test_9.shape[0]), 9)\n",
        "\n",
        "y_test_mc = np.concatenate((y_test_0, y_test_1, y_test_2, y_test_3, y_test_4, y_test_5, y_test_6, y_test_7, y_test_8, y_test_9), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZRFS7ps_nR",
        "colab_type": "text"
      },
      "source": [
        "### Normalize features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmzOmf9zs_nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_max = np.max(np.concatenate((X_train_0, X_train_1, X_train_2, X_train_3, X_train_4, X_train_5, X_train_6, X_train_7, X_train_8, X_train_9), axis=0), axis=0)\n",
        "feat_min = np.min(np.concatenate((X_train_0, X_train_1, X_train_2, X_train_3, X_train_4, X_train_5, X_train_6, X_train_7, X_train_8, X_train_9), axis=0), axis=0)\n",
        "\n",
        "X_train_0_normalized = (X_train_0 - feat_min) / (feat_max - feat_min)\n",
        "X_train_1_normalized = (X_train_1 - feat_min) / (feat_max - feat_min)\n",
        "X_train_2_normalized = (X_train_2 - feat_min) / (feat_max - feat_min)\n",
        "X_train_3_normalized = (X_train_3 - feat_min) / (feat_max - feat_min)\n",
        "X_train_4_normalized = (X_train_4 - feat_min) / (feat_max - feat_min)\n",
        "X_train_5_normalized = (X_train_5 - feat_min) / (feat_max - feat_min)\n",
        "X_train_6_normalized = (X_train_6 - feat_min) / (feat_max - feat_min)\n",
        "X_train_7_normalized = (X_train_7 - feat_min) / (feat_max - feat_min)\n",
        "X_train_8_normalized = (X_train_8 - feat_min) / (feat_max - feat_min)\n",
        "X_train_9_normalized = (X_train_9 - feat_min) / (feat_max - feat_min)\n",
        "\n",
        "X_train_mc_normalized = np.concatenate((X_train_0_normalized, X_train_1_normalized, X_train_2_normalized, X_train_3_normalized, X_train_4_normalized, X_train_5_normalized, X_train_6_normalized, X_train_7_normalized, X_train_8_normalized, X_train_9_normalized), axis=0)\n",
        "\n",
        "X_test_0_normalized = (X_test_0 - feat_min) / (feat_max - feat_min)\n",
        "X_test_1_normalized = (X_test_1 - feat_min) / (feat_max - feat_min)\n",
        "X_test_2_normalized = (X_test_2 - feat_min) / (feat_max - feat_min)\n",
        "X_test_3_normalized = (X_test_3 - feat_min) / (feat_max - feat_min)\n",
        "X_test_4_normalized = (X_test_4 - feat_min) / (feat_max - feat_min)\n",
        "X_test_5_normalized = (X_test_5 - feat_min) / (feat_max - feat_min)\n",
        "X_test_6_normalized = (X_test_6 - feat_min) / (feat_max - feat_min)\n",
        "X_test_7_normalized = (X_test_7 - feat_min) / (feat_max - feat_min)\n",
        "X_test_8_normalized = (X_test_8 - feat_min) / (feat_max - feat_min)\n",
        "X_test_9_normalized = (X_test_9 - feat_min) / (feat_max - feat_min)\n",
        "\n",
        "X_test_mc_normalized = np.concatenate((X_test_0_normalized, X_test_1_normalized, X_test_2_normalized, X_test_3_normalized, X_test_4_normalized, X_test_5_normalized, X_test_6_normalized, X_test_7_normalized, X_test_8_normalized, X_test_9_normalized), axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYSH8zmGs_nV",
        "colab_type": "text"
      },
      "source": [
        "### Define and train a model for each couple of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr4xFDcws_nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Builds SVM classifier, play with the paramenters! look here: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html \n",
        "SVM_parameters={\n",
        "    'C': 1,\n",
        "    'kernel': 'poly',\n",
        "    'degree': 3,\n",
        "    'decision_function_shape' : 'ovo',\n",
        "    'probability' : True\n",
        "}\n",
        "\n",
        "clf = sklearn.svm.SVC(**SVM_parameters)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSbuYmiks_nY",
        "colab_type": "code",
        "outputId": "70fc15c0-a1d9-41da-93d5-b93d8bfaf8d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#fits the model\n",
        "clf.fit(X_train_mc_normalized, y_train_mc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='poly',\n",
              "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vujtcrEqs_nb",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate each classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5QL_7qms_nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_predicted = clf.predict(X_test_mc_normalized).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOTy9_Vbs_nd",
        "colab_type": "text"
      },
      "source": [
        "### Majority voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXnvlkk0s_ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_predicted_mc = np.array(y_test_predicted, dtype=np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8gUPGgGs_ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_predicted_mv = np.zeros((y_test_predicted_mc.shape[0],))\n",
        "for i, e in enumerate(y_test_predicted_mc):\n",
        "    y_test_predicted_mv[i] = np.bincount(e).argmax() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA15eSXPs_nk",
        "colab_type": "text"
      },
      "source": [
        "### *Exercise 3* : Compute confusion matrix for multiclass\n",
        "Compute and print the confusion matrix when more than 2 classes are presents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrpN4qvRs_nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cm_multiclass(gt, predicted):\n",
        "    classes = np.unique(gt)\n",
        "    \n",
        "    CM = np.zeros((len(classes), len(classes)))\n",
        "    \n",
        "    for i in np.arange(len(classes)):\n",
        "        pred_class = predicted[gt==i]\n",
        "        \n",
        "        for j in np.arange(len(pred_class)):\n",
        "            CM[i, int(pred_class[j])] = CM[i, int(pred_class[j])] + 1 \n",
        "    print(CM)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbgdpR8ls_nn",
        "colab_type": "code",
        "outputId": "184f20ce-a3a7-4b50-a448-932517b833ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "compute_cm_multiclass(y_test_mc, y_test_predicted_mv)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[19.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. 20.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. 20.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0. 18.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. 20.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. 20.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0. 19.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0. 20.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0. 20.  0.]\n",
            " [ 1.  1.  0.  0.  0.  1.  0.  0.  0. 17.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}