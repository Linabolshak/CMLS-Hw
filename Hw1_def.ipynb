{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "Hw1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mUOrAYas_mL",
        "colab_type": "text"
      },
      "source": [
        "# Spoken digit classification using Support-Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkd5eD5Ys_mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.svm\n",
        "import IPython.display as ipd\n",
        "import scipy as sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vKqvXRyIIba",
        "colab_type": "code",
        "outputId": "539a9411-41eb-4523-8398-73b667d2617f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git #directly clone the directory from github"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'free-spoken-digit-dataset'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 3166 (delta 3), reused 8 (delta 3), pack-reused 3157\u001b[K\n",
            "Receiving objects: 100% (3166/3166), 23.93 MiB | 26.26 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax7y26_ks_mR",
        "colab_type": "text"
      },
      "source": [
        "# Features computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQfbtZM8QtPo",
        "colab_type": "text"
      },
      "source": [
        "### MFCC computation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwcXOr9_s_mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_mfcc(audio, fs, n_mfcc):\n",
        "    # Compute the spectrogram of the audio signal\n",
        "    X = np.abs(librosa.stft(\n",
        "        audio,\n",
        "        window='hamming',\n",
        "        n_fft=1024,\n",
        "        hop_length=512,)\n",
        "        )\n",
        "    \n",
        "    # Find the weights of the mel filters\n",
        "    mel = librosa.filters.mel(\n",
        "        sr=fs,\n",
        "        n_fft=1024,\n",
        "        n_mels=40,\n",
        "        fmin=133.33,\n",
        "        fmax=6853.8,\n",
        "    )\n",
        "    # Apply the filters to spectrogram\n",
        "    melspectrogram = np.dot(mel, X)\n",
        "    # Take the logarithm\n",
        "    log_melspectrogram = np.log10(melspectrogram + 1e-16)\n",
        "    \n",
        "    # Apply the DCT to log melspectrogram to obtain the coefficients\n",
        "    mfcc = sp.fftpack.dct(log_melspectrogram, axis=0, norm='ortho')[1:n_mfcc+1]\n",
        "    return mfcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PeXRTB-s_mV",
        "colab_type": "text"
      },
      "source": [
        "### Compute training features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL3mBDL7s_mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "test = []\n",
        "train = []\n",
        "n_mfcc = 13\n",
        "dict_train_files = {'0': [], '1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': [], '8': [], '9': []}\n",
        "dict_train_features = {'0': [], '1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': [], '8': [], '9': []}\n",
        "\n",
        "train_root = 'free-spoken-digit-dataset/recordings'\n",
        "class_train_files = [f for f in os.listdir(train_root) if f.endswith('.wav')] #outputs a list with the filename of every file in train_root\n",
        "\n",
        "#Splits dataset in test and train\n",
        "for f in class_train_files:\n",
        "  first_split = f.rsplit(\"_\", 1)[1]\n",
        "  second_split = first_split.rsplit(\".\", 1)[0]\n",
        "  if int(second_split) <= 4:\n",
        "      test.append(f)\n",
        "  else:\n",
        "      train.append(f)\n",
        "\n",
        "#Puts files name in dict_train_files according to class\n",
        "for c in classes:\n",
        "  for f in train:\n",
        "    split = f.rsplit(\"_\", 2)[0]\n",
        "    if int(c) == int(split):\n",
        "      dict_train_files[c].append(f)\n",
        "\n",
        "#Computes feature matrix according to class and puts it into dict_train_features\n",
        "for c in dict_train_files:\n",
        "  \n",
        "  train_features = np.zeros((len(dict_train_files[c]), n_mfcc)) # \n",
        "  \n",
        "  for index, f in enumerate(dict_train_files[c]):\n",
        "    audio, fs = librosa.load(os.path.join(train_root, f), sr=None)\n",
        "    mfcc = compute_mfcc(audio, fs, n_mfcc)\n",
        "    train_features[index, :] = np.mean(mfcc, axis=1)\n",
        "    \n",
        "    dict_train_features[c] = train_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16W94wkZs_me",
        "colab_type": "text"
      },
      "source": [
        "### Compute test features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXR_JRFds_mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#same as above for test set\n",
        "dict_test_files = {'0': [], '1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': [], '8': [], '9': []}\n",
        "dict_test_features = {'0': [], '1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': [], '8': [], '9': []}\n",
        "\n",
        "for c in classes:\n",
        "  for f in test:\n",
        "    splitto = f.rsplit(\"_\", 2)[0]\n",
        "    if int(c) == int(splitto):\n",
        "      dict_test_files[c].append(f)\n",
        "\n",
        "\n",
        "for c in dict_test_files:\n",
        "  \n",
        "  n_test_samples = len(dict_test_files[c]) #outputs length of class_train_files \n",
        "  \n",
        "  test_features = np.zeros((n_test_samples, n_mfcc))  \n",
        "  \n",
        "  for index, f in enumerate(dict_test_files[c]):\n",
        "    audio, fs = librosa.load(os.path.join(train_root, f), sr=None)\n",
        "    mfcc = compute_mfcc(audio, fs, n_mfcc)\n",
        "    test_features[index, :] = np.mean(mfcc, axis=1)\n",
        "    \n",
        "  dict_test_features[c] = test_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-TsMwwps_ml",
        "colab_type": "text"
      },
      "source": [
        "### Feature visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qQH4Bw45s_mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for c in classes:\n",
        "    mfcc = dict_train_features[c].transpose()\n",
        "    # Visualization\n",
        "    fig = plt.figure(figsize=(16, 6))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(mfcc, origin='lower', aspect='auto')\n",
        "    plt.xlabel('Training samples')\n",
        "    plt.ylabel('MFCC coefficients')\n",
        "    plt.title('MFCC (coefficients 0 to 13) for class {}'.format(c))\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    mfcc_upper = mfcc[4:]\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mfcc_upper, origin='lower', aspect='auto')\n",
        "    plt.title('MFCC (coefficients 4 to 13) for class {}'.format(c))\n",
        "    plt.xlabel('Training samples')\n",
        "    plt.ylabel('MFCC coefficients')\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqhR_03bs_nL",
        "colab_type": "text"
      },
      "source": [
        "# Classifier (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbTQgZbTs_nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_0 = '0'\n",
        "class_1 = '1'\n",
        "class_2 = '2'\n",
        "class_3 = '3'\n",
        "class_4 = '4'\n",
        "class_5 = '5'\n",
        "class_6 = '6'\n",
        "class_7 = '7'\n",
        "class_8 = '8'\n",
        "class_9 = '9'\n",
        "\n",
        "#Training\n",
        "X_train_0 = dict_train_features[class_0]\n",
        "X_train_1 = dict_train_features[class_1]\n",
        "X_train_2 = dict_train_features[class_2]\n",
        "X_train_3 = dict_train_features[class_3]\n",
        "X_train_4 = dict_train_features[class_4]\n",
        "X_train_5 = dict_train_features[class_5]\n",
        "X_train_6 = dict_train_features[class_6]\n",
        "X_train_7 = dict_train_features[class_7]\n",
        "X_train_8 = dict_train_features[class_8]\n",
        "X_train_9 = dict_train_features[class_9]\n",
        "\n",
        "y_train_0 = np.zeros((X_train_0.shape[0]))\n",
        "y_train_1 = np.ones((X_train_1.shape[0]))\n",
        "y_train_2 = np.full((X_train_2.shape[0]), 2)\n",
        "y_train_3 = np.full((X_train_3.shape[0]), 3)\n",
        "y_train_4 = np.full((X_train_4.shape[0]), 4)\n",
        "y_train_5 = np.full((X_train_5.shape[0]), 5)\n",
        "y_train_6 = np.full((X_train_6.shape[0]), 6)\n",
        "y_train_7 = np.full((X_train_7.shape[0]), 7)\n",
        "y_train_8 = np.full((X_train_8.shape[0]), 8)\n",
        "y_train_9 = np.full((X_train_9.shape[0]), 9)\n",
        "\n",
        "y_train_mc = np.concatenate((y_train_0, y_train_1, y_train_2, y_train_3, y_train_4, y_train_5, y_train_6, y_train_7, y_train_8, y_train_9), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RIdle9Os_nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing\n",
        "X_test_0 = dict_test_features[class_0]\n",
        "X_test_1 = dict_test_features[class_1]\n",
        "X_test_2 = dict_test_features[class_2]\n",
        "X_test_3 = dict_test_features[class_3]\n",
        "X_test_4 = dict_test_features[class_4]\n",
        "X_test_5 = dict_test_features[class_5]\n",
        "X_test_6 = dict_test_features[class_6]\n",
        "X_test_7 = dict_test_features[class_7]\n",
        "X_test_8 = dict_test_features[class_8]\n",
        "X_test_9 = dict_test_features[class_9]\n",
        "\n",
        "y_test_0 = np.zeros((X_test_0.shape[0]))\n",
        "y_test_1 = np.ones((X_test_1.shape[0]))\n",
        "y_test_2 = np.full((X_test_2.shape[0]), 2)\n",
        "y_test_3 = np.full((X_test_3.shape[0]), 3)\n",
        "y_test_4 = np.full((X_test_4.shape[0]), 4)\n",
        "y_test_5 = np.full((X_test_5.shape[0]), 5)\n",
        "y_test_6 = np.full((X_test_6.shape[0]), 6)\n",
        "y_test_7 = np.full((X_test_7.shape[0]), 7)\n",
        "y_test_8 = np.full((X_test_8.shape[0]), 8)\n",
        "y_test_9 = np.full((X_test_9.shape[0]), 9)\n",
        "\n",
        "y_test_mc = np.concatenate((y_test_0, y_test_1, y_test_2, y_test_3, y_test_4, y_test_5, y_test_6, y_test_7, y_test_8, y_test_9), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZRFS7ps_nR",
        "colab_type": "text"
      },
      "source": [
        "### Normalize features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmzOmf9zs_nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_max = np.max(np.concatenate((X_train_0, X_train_1, X_train_2, X_train_3, X_train_4, X_train_5, X_train_6, X_train_7, X_train_8, X_train_9), axis=0), axis=0)\n",
        "feat_min = np.min(np.concatenate((X_train_0, X_train_1, X_train_2, X_train_3, X_train_4, X_train_5, X_train_6, X_train_7, X_train_8, X_train_9), axis=0), axis=0)\n",
        "\n",
        "X_train_0_normalized = (X_train_0 - feat_min) / (feat_max - feat_min)\n",
        "X_train_1_normalized = (X_train_1 - feat_min) / (feat_max - feat_min)\n",
        "X_train_2_normalized = (X_train_2 - feat_min) / (feat_max - feat_min)\n",
        "X_train_3_normalized = (X_train_3 - feat_min) / (feat_max - feat_min)\n",
        "X_train_4_normalized = (X_train_4 - feat_min) / (feat_max - feat_min)\n",
        "X_train_5_normalized = (X_train_5 - feat_min) / (feat_max - feat_min)\n",
        "X_train_6_normalized = (X_train_6 - feat_min) / (feat_max - feat_min)\n",
        "X_train_7_normalized = (X_train_7 - feat_min) / (feat_max - feat_min)\n",
        "X_train_8_normalized = (X_train_8 - feat_min) / (feat_max - feat_min)\n",
        "X_train_9_normalized = (X_train_9 - feat_min) / (feat_max - feat_min)\n",
        "\n",
        "X_train_mc_normalized = np.concatenate((X_train_0_normalized, X_train_1_normalized, X_train_2_normalized, X_train_3_normalized, X_train_4_normalized, X_train_5_normalized, X_train_6_normalized, X_train_7_normalized, X_train_8_normalized, X_train_9_normalized), axis=0)\n",
        "\n",
        "X_test_0_normalized = (X_test_0 - feat_min) / (feat_max - feat_min)\n",
        "X_test_1_normalized = (X_test_1 - feat_min) / (feat_max - feat_min)\n",
        "X_test_2_normalized = (X_test_2 - feat_min) / (feat_max - feat_min)\n",
        "X_test_3_normalized = (X_test_3 - feat_min) / (feat_max - feat_min)\n",
        "X_test_4_normalized = (X_test_4 - feat_min) / (feat_max - feat_min)\n",
        "X_test_5_normalized = (X_test_5 - feat_min) / (feat_max - feat_min)\n",
        "X_test_6_normalized = (X_test_6 - feat_min) / (feat_max - feat_min)\n",
        "X_test_7_normalized = (X_test_7 - feat_min) / (feat_max - feat_min)\n",
        "X_test_8_normalized = (X_test_8 - feat_min) / (feat_max - feat_min)\n",
        "X_test_9_normalized = (X_test_9 - feat_min) / (feat_max - feat_min)\n",
        "\n",
        "X_test_mc_normalized = np.concatenate((X_test_0_normalized, X_test_1_normalized, X_test_2_normalized, X_test_3_normalized, X_test_4_normalized, X_test_5_normalized, X_test_6_normalized, X_test_7_normalized, X_test_8_normalized, X_test_9_normalized), axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYSH8zmGs_nV",
        "colab_type": "text"
      },
      "source": [
        "### Define and train a model for each couple of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr4xFDcws_nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Builds SVM classifier\n",
        "SVM_parameters={\n",
        "    'C': 1,\n",
        "    'kernel': 'rbf',\n",
        "    'decision_function_shape' : 'ovo',\n",
        "    'probability' : True\n",
        "}\n",
        "\n",
        "clf = sklearn.svm.SVC(**SVM_parameters)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSbuYmiks_nY",
        "colab_type": "code",
        "outputId": "648364c2-db6f-4896-f45f-869591a0d52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#fits the model\n",
        "clf.fit(X_train_mc_normalized, y_train_mc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vujtcrEqs_nb",
        "colab_type": "text"
      },
      "source": [
        "### Make a prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5QL_7qms_nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_predicted = clf.predict(X_test_mc_normalized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA15eSXPs_nk",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrpN4qvRs_nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cm_multiclass(gt, predicted):\n",
        "    classes = np.unique(gt)\n",
        "    \n",
        "    CM = np.zeros((len(classes), len(classes)))\n",
        "    \n",
        "    for i in np.arange(len(classes)):\n",
        "        pred_class = predicted[gt==i]\n",
        "        \n",
        "        for j in np.arange(len(pred_class)):\n",
        "            CM[i, int(pred_class[j])] = CM[i, int(pred_class[j])] + 1 \n",
        "    print(CM)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbgdpR8ls_nn",
        "colab_type": "code",
        "outputId": "933a28ef-7927-40b3-83ab-dfde3d49d6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "compute_cm_multiclass(y_test_mc, y_test_predicted)\n",
        "#returns and prints the classifier accuracy\n",
        "sc = clf.score(X_test_mc_normalized, y_test_mc)*100\n",
        "print (\"The classifier accuracy is: \"+str(round(sc, 2)) +\"%\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[20.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. 19.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. 20.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1. 18.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. 20.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. 20.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0. 20.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0. 20.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0. 20.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.  0.  0. 19.]]\n",
            "The classifier accuracy is: 98.0%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}